{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "%matplotlib inline\n",
    "\n",
    "from datasets import load_mnist, download_mnist\n",
    "from mygrad.nnet.layers.pooling import max_pool\n",
    "from mygrad.tensor_manip.tiling.funcs import repeat\n",
    "\n",
    "from mynn.layers import conv\n",
    "from mynn.activations import relu, sigmoid\n",
    "from mynn.losses import mean_squared_loss\n",
    "from mynn.initializers import glorot_uniform\n",
    "from mynn.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "download_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_data, train_labels, val_data, val_labels = load_mnist()\n",
    "\n",
    "train_data = train_data / 255 # [0, 255] -> [0, 1]\n",
    "val_data = val_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\" A simple auto-encoder. \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        init = glorot_uniform\n",
    "        args = {'gain': np.sqrt(2)}\n",
    "        self.conv11 = conv(1, 8, 3, 3, padding=1, weight_initializer=init, weight_kwargs=args)\n",
    "        self.conv21 = conv(8, 16, 3, 3, padding=1, weight_initializer=init, weight_kwargs=args)\n",
    "        self.conv31 = conv(16, 16, 3, 3, padding=1, weight_initializer=init, weight_kwargs=args)\n",
    "        self.conv4 = conv(16, 16, 3, 3, padding=1, weight_initializer=init, weight_kwargs=args)\n",
    "        self.conv32 = conv(16, 16, 3, 3, padding=1, weight_initializer=init, weight_kwargs=args)\n",
    "        self.conv22 = conv(16, 8, 3, 3, padding=1, weight_initializer=init, weight_kwargs=args)\n",
    "        self.conv12 = conv(8, 1, 3, 3, padding=1, weight_initializer=init, weight_kwargs=args)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\" Perform a forward pass of the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : Union[numpy.ndarray, mygrad.Tensor]\n",
    "            The data to send through the model.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        mygrad.Tensor\n",
    "            The reconstructed input.\n",
    "        \"\"\"\n",
    "        x = relu(self.conv21(relu(self.conv11(x))))\n",
    "        x = max_pool(x, (2, 2), 2)                   # 28x28 -> 14x14\n",
    "        x = relu(self.conv31(x))\n",
    "        x = max_pool(x, (2, 2), 2)                   # 14x14 -> 7x7\n",
    "        x = relu(self.conv4(x))\n",
    "        x = repeat(repeat(x, 2, axis=2), 2, axis=3)  # 7x7 -> 14x14\n",
    "        x = relu(self.conv22(relu(self.conv32(x))))\n",
    "        x = repeat(repeat(x, 2, axis=2), 2, axis=3)  # 14x14 -> 28x28\n",
    "        x = sigmoid(self.conv12(x))\n",
    "        return x\n",
    "        \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        \"\"\" Access the parameters of the model.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[mygrad.Tensor, ...]\n",
    "            The parameters of the model.\n",
    "        \"\"\"\n",
    "        params = []\n",
    "        for layer in (\n",
    "            self.conv11,\n",
    "            self.conv21,\n",
    "            self.conv31,\n",
    "            self.conv4,\n",
    "            self.conv12,\n",
    "            self.conv22,\n",
    "            self.conv32,\n",
    "        ):\n",
    "            params += list(layer.parameters)\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "m = Model()\n",
    "optim = Adam(m.parameters, learning_rate=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(batch_size=128):\n",
    "    \"\"\" Train the model for one epoch. \"\"\"\n",
    "    idxs = np.arange(len(train_data)) # shuffle our data\n",
    "    np.random.shuffle(idxs)\n",
    "    \n",
    "    for batch in range(0, len(idxs), batch_size):\n",
    "        data = train_data[idxs[batch:batch+batch_size]]\n",
    "        outs = m(data)                        # get the model output\n",
    "        loss = mean_squared_loss(outs, data)  # compute the loss\n",
    "        loss.backward()                       # backpropagate the loss\n",
    "        optim.step()                          # update the model weights\n",
    "        loss.null_gradients()                 # clear the gradients\n",
    "        print(f\"Batch {batch // batch_size} / {len(idxs) // batch_size}: loss {loss.data:0.4f}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    print(f\"Starting epoch {epoch}\")\n",
    "    train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 8))\n",
    "idx = np.random.randint(len(train_data))\n",
    "ax[0].imshow(train_data[idx].squeeze(), \"gray\")\n",
    "ax[0].set_title(\"Original\")\n",
    "\n",
    "out = m(train_data[idx][np.newaxis])\n",
    "ax[1].imshow(out.data.squeeze(), \"gray\")\n",
    "ax[1].set_title(\"Reconstructed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "name": "mnist-autoencoder.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
